{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "triplet_loss_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pthinh14/triplet-loss/blob/master/triplet_loss_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6xAfgKO2Evw",
        "colab_type": "code",
        "outputId": "fdcc8fc2-95bf-4dab-89a5-3ffb47f90b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Tm_7ZHGeML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes_per_batch = 4\n",
        "num_images_per_class = 8\n",
        "base_path= './drive/My Drive/IKEA/'\n",
        "IMG_TYPES = ['.png', '.jpg']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KapU6M-5Gb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %pip install tensorflow==1.13.1\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.applications.inception_v3 as kai\n",
        "import tensorflow.keras.layers as kl\n",
        "import tensorflow.keras.models as km\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "## required for semi-hard triplet loss:\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.framework import dtypes\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def triplet_loss(y_true, y_pred):\n",
        "    y_pred = K.l2_normalize(y_pred,axis=1)\n",
        "    batch = 2\n",
        "    ref1 = y_pred[0:1,:]\n",
        "    pos1 = y_pred[1:num_images_per_class,:]\n",
        "    neg1 = y_pred[num_images_per_class:,:]\n",
        "    dis_pos = K.sum(K.square(ref1 - pos1), axis=1, keepdims=True)\n",
        "    dis_neg = K.sum(K.square(ref1 - neg1), axis=1, keepdims=True)\n",
        "    dis_pos = K.sqrt(dis_pos)\n",
        "    dis_neg = K.sqrt(dis_neg)\n",
        "    a1 = 0.6\n",
        "    d1 = K.maximum(0.0,dis_pos-dis_neg+a1)\n",
        "    return K.mean(d1)\n",
        "\n",
        "\n",
        "def build_model(image_shape=(640, 640, 3), embedding_length=128, trainable=True):\n",
        "    backbone = kai.InceptionV3(input_shape=image_shape, include_top=False)\n",
        "    backbone.trainable = trainable\n",
        "    x = kl.GlobalMaxPooling2D()(backbone.output)\n",
        "    x = kl.Dense(embedding_length * 2)(x)\n",
        "    x = kl.Dense(embedding_length)(x)\n",
        "    embedding = kl.Dense(embedding_length, name='embedding')(x)\n",
        "    model = km.Model(inputs=[backbone.input], outputs=[embedding])\n",
        "    # opt = tf.train.AdamOptimizer(0.0001)\n",
        "    model.compile(loss=triplet_loss, optimizer='adam')\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg0FCdxMAaD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import skimage.transform\n",
        "IMG_SIZE = 640\n",
        "def load_image(filename):\n",
        "    # print(filename)\n",
        "    # # raw = cv2.imread(filename)\n",
        "    # # label = os.path.dirname(filename).split(\"/\")[-2] +\"/\"+ os.path.dirname(filename).split(\"/\")[-1]\n",
        "    \n",
        "    # # print(label)\n",
        "    # filename_queue = tf.train.string_input_producer(filenames)\n",
        "    # reader = tf.WholeFileReader()\n",
        "    # key, value = reader.read(filename_queue)\n",
        "\n",
        "    # images = tf.image.decode_jpeg(value, channels=3)\n",
        "    # return images\n",
        "    # # if len(raw.shape) == 2:\n",
        "    # #     raw = np.stack((raw,)*3, axis=-1)\n",
        "    # # elif len(raw.shape) > 2 and raw.shape[2] == 4:\n",
        "    # #     #convert the image from RGBA2RGB\n",
        "    # #     raw = cv2.cvtColor(raw, cv2.COLOR_BGRA2BGR)\n",
        "    # # curr_crop = skimage.transform.rescale(raw, size / max(len(raw), len(raw[0])),\n",
        "    # #                                         mode='constant', multichannel=True)\n",
        "    # # return np.pad(curr_crop, ((0, size - len(curr_crop)), (0, size - len(curr_crop[0])), (0, 0)),\n",
        "    # #                 mode='constant'), label\n",
        "    # # return image, label\n",
        "    image_string = tf.read_file(filename)\n",
        "\n",
        "    #Don't use tf.image.decode_image, or the output shape will be undefined\n",
        "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
        "\n",
        "    #This will convert to float values in [0, 1]\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "    resized_image = tf.image.resize_images(image, [64, 64])\n",
        "    return resized_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDuawMIxEN-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %pip install tf-nightly\n",
        "import sys\n",
        "import keras.utils as ku\n",
        "import keras.callbacks as KC\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac1uko9UWXKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tfdata_generator(images, labels, is_training, batch_size=128):\n",
        "    '''Construct a data generator using tf.Dataset'''\n",
        "\n",
        "    def preprocess_fn(image, label):\n",
        "        '''A transformation function to preprocess raw data\n",
        "        into trainable input. '''\n",
        "        x = tf.reshape(tf.cast(image, tf.float32), (28, 28, 1))\n",
        "        y = tf.one_hot(tf.cast(label, tf.uint8), _NUM_CLASSES)\n",
        "        return x, y\n",
        "\n",
        "    #  A Dataset of strings corresponding to file names.\n",
        "    datasets = [tf.data.Dataset.list_files(\"{}/*.png\".format(base_path + image_dir)) for image_dir in image_classes]\n",
        "\n",
        "    def generator():\n",
        "        while True:\n",
        "            # Sample the labels that will compose the batch\n",
        "            labels = np.random.choice(range(num_labels),\n",
        "                                        num_classes_per_batch,\n",
        "                                        replace=False)\n",
        "            for label in labels:\n",
        "                for _ in range(num_images_per_class):\n",
        "                    # yield images[label][np.random.choice(range(num_images_per_class))]\n",
        "                    yield label\n",
        "\n",
        "    choice_dataset = tf.data.Dataset.from_generator(generator, tf.int64).repeat()\n",
        "    dataset = tf.data.experimental.choose_from_datasets(datasets, choice_dataset)\n",
        "    # def my_generator(batch_size):\n",
        "    #     foo = np.zeros((batch_size,))\n",
        "\n",
        "    #     for images, ids in data.generator(batch_size):\n",
        "    #         yield images, foo\n",
        "    dataset = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(1)\n",
        "    iterator = dataset.make_initializable_iterator()\n",
        "\n",
        "    iterator_init_op = iterator.initializer\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    if is_training:\n",
        "        dataset = dataset.shuffle(1000)  # depends on sample size\n",
        "\n",
        "    # Transform and batch data at the same time\n",
        "    dataset = dataset.apply(tf.contrib.data.map_and_batch(\n",
        "        preprocess_fn, batch_size,\n",
        "        num_parallel_batches=4,  # cpu cores\n",
        "        drop_remainder=True if is_training else False))\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.prefetch(tf.contrib.data.AUTOTUNE)\n",
        "\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w32R9I2d5MXt",
        "colab_type": "code",
        "outputId": "3d96a55c-3545-4fd6-f903-409fdcfa74d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "\n",
        "# try:\n",
        "#     device_name = os.environ[\"COLAB_TPU_ADDR\"]\n",
        "#     TPU_ADDRESS = \"grpc://\" + device_name\n",
        "#     print(\"Found TPU at: {}\".format(TPU_ADDRESS))\n",
        "# except KeyError:\n",
        "#     print(\"TPU not found\")\n",
        "\n",
        "print(len(sys.argv))\n",
        "print(\"hello world\")\n",
        "\n",
        "# data = DataLoader()\n",
        "model = build_model(trainable=True)\n",
        "\n",
        "\n",
        "# total_num_images = data.get_total_num_images()\n",
        "STEPS_PER_EPOCH = 10\n",
        "\n",
        "batch_size = num_classes_per_batch*num_images_per_class\n",
        "\n",
        "path = base_path\n",
        "directories = os.listdir(path)\n",
        "images = {}\n",
        "image_classes = []\n",
        "for directory in directories:\n",
        "    sub_dirs = os.listdir(base_path + directory)\n",
        "    for sub_dir in sub_dirs:\n",
        "        cur_path = os.path.join(base_path + directory, sub_dir)\n",
        "        _, _, filenames = next(os.walk(cur_path))\n",
        "        for filename in filenames:\n",
        "            if os.path.splitext(filename)[1] in IMG_TYPES:\n",
        "                if directory +'/'+ sub_dir in images:\n",
        "                    images[directory +'/'+ sub_dir].append(os.path.join(cur_path, filename))\n",
        "                else:\n",
        "                    images[directory +'/'+ sub_dir] = [os.path.join(cur_path, filename)]\n",
        "                    image_classes.append(directory +'/'+ sub_dir)\n",
        "\n",
        "# image_classes = (sub_sub_dirs for sub_sub_dirs in (os.listdir(base_path + sub_dir) for sub_dir in directories))\n",
        "# images = {image_class: filename for filename in next(os.walk(os.path.join(base_path, image_class)) if os.path.splitext(filename)[1] in IMG_TYPES for image_class in image_classes}\n",
        "datasets = [tf.data.Dataset.list_files(\"{}/*.png\".format(base_path + image_dir)) for image_dir in image_classes]\n",
        "# per_class_datasets = [tf.data.TFRecordDataset(tf.data.Dataset.list_files(d)) for d in directories]\n",
        "\n",
        "# datasets, image_classes = load_data()\n",
        "num_labels=len(image_classes)\n",
        "print(num_labels)\n",
        "\n",
        "def generator():\n",
        "    while True:\n",
        "        # Sample the labels that will compose the batch\n",
        "        labels = np.random.choice(range(num_labels),\n",
        "                                    num_classes_per_batch,\n",
        "                                    replace=False)\n",
        "        for label in labels:\n",
        "            for _ in range(num_images_per_class):\n",
        "                # yield images[label][np.random.choice(range(num_images_per_class))]\n",
        "                yield label\n",
        "\n",
        "choice_dataset = tf.data.Dataset.from_generator(generator, tf.int64).repeat()\n",
        "dataset = tf.data.experimental.choose_from_datasets(datasets, choice_dataset)\n",
        "# def my_generator(batch_size):\n",
        "#     foo = np.zeros((batch_size,))\n",
        "\n",
        "#     for images, ids in data.generator(batch_size):\n",
        "#         yield images, foo\n",
        "dataset = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "dataset = dataset.batch(batch_size)\n",
        "dataset = dataset.prefetch(1)\n",
        "iterator = dataset.make_initializable_iterator()\n",
        "\n",
        "iterator_init_op = iterator.initializer\n",
        "\n",
        "\n",
        "checkpt = KC.ModelCheckpoint('./weights.{epoch:02d}-{loss:.2f}.hdf5',\n",
        "                             monitor='loss',\n",
        "                             verbose=0,\n",
        "                             save_best_only=False, \n",
        "                             mode='auto',\n",
        "                             period=1)\n",
        "history = model.fit_generator(iterator.get_next(),\n",
        "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                    epochs=20,\n",
        "                    validation_data=None,\n",
        "                    validation_steps=None,\n",
        "                    callbacks=[checkpt],\n",
        "                    class_weight=None,\n",
        "                    max_queue_size=10,\n",
        "                    workers=1,\n",
        "                    use_multiprocessing=False,\n",
        "                    shuffle=False)\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "hello world\n",
            "219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-2abd528ba2e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m                     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                     shuffle=False)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# Plot training & validation loss values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m       shuffle=shuffle)\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mconvert_to_generator_like\u001b[0;34m(data, batch_size, steps_per_epoch, epochs, shuffle)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m   \u001b[0;31m# Create generator from NumPy or EagerTensor Input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m   \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     raise ValueError(\n",
            "\u001b[0;31mTypeError\u001b[0m: __int__ returned non-int (type NoneType)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvgBMHpnV3r3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# iterator_helper = datasets[0].make_one_shot_iterator()\n",
        "with tf.Session() as sess:\n",
        "    filename_temp = iterator_helper.get_next()\n",
        "    print(sess.run(filename_temp))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}